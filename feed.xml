<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://renwuli.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://renwuli.github.io/" rel="alternate" type="text/html" hreflang="en" /><updated>2023-04-26T00:19:13+00:00</updated><id>https://renwuli.github.io/feed.xml</id><title type="html">Ren-Wu Li</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
</subtitle><entry><title type="html">ORBSLAM3 All in One</title><link href="https://renwuli.github.io/blog/2023/ORBSLAM3-All-in-One/" rel="alternate" type="text/html" title="ORBSLAM3 All in One" /><published>2023-04-10T14:00:00+00:00</published><updated>2023-04-10T14:00:00+00:00</updated><id>https://renwuli.github.io/blog/2023/ORBSLAM3-All-in-One</id><content type="html" xml:base="https://renwuli.github.io/blog/2023/ORBSLAM3-All-in-One/"><![CDATA[<p>写这篇文章的初衷有两个，一是目前的简中互联网实在是没有对ORBSLAM3庖丁解牛解析很全面的博客，尽管有很多从理论和代码层面都分析的不错的文章和视频，还有开源的带注释的源码，但都不够系统，且有些资源是收费的；二是想要消化一下对ORBSLAM3，加深对此算法的理解，做到知其然并知其所以然。我希望能够通过我这篇长文，能够让希望了解ORBSLAM3算法的朋友不用再费心费力去找别的资料，一文就能搞懂理论和代码，所以我给这篇文章起了个题目：<em>ORBSLAM3 All in One</em>。</p>

<p>不同于其他文章可能会上来就讲前端，诸如ORB特征点是什么啊，为什么ORB特征具有旋转不变性啊，怎么用八叉树均匀地将特征点铺满整张图上啊，我觉得这些问题都非常细，一上来就看这些容易让人陷入局部极小值跳不出来，无法从宏观的角度去俯瞰整个世界，导致对ORBSLAM3失去兴趣。我将会以 <em>算法总览</em> – <em>算法详解</em> – <em>问题</em> 的思路，去介绍ORBSLAM3。</p>

<h2 id="算法总览">算法总览</h2>

<p>看到这篇文章的朋友应该都已经将ORBSLAM3的文章读过了，如果还没有读过的话，最好先赶紧去读一遍再说：<a href="https://arxiv.org/pdf/2007.11898.pdf">https://arxiv.org/pdf/2007.11898.pdf</a></p>

<h3 id="传感器支持">传感器支持</h3>

<table>
  <thead>
    <tr>
      <th style="text-align: center">相机模型</th>
      <th style="text-align: center">相机组合</th>
      <th style="text-align: center">运行模式</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">针孔相机<br />鱼眼相机</td>
      <td style="text-align: center">单目<br />双目<br />RGB-D</td>
      <td style="text-align: center">视觉（Visual SLAM）<br />视觉-惯性（Visual-Inertial SLAM）</td>
    </tr>
  </tbody>
</table>

<p>从上表中可以看到 ORBSLAM3支持的传感器和运行模式那是相当丰富。当然，如果本文将以上的运行模式全都介绍一遍那是相当的冗余和啰嗦，所以本文以 <em>单目-针孔相机-视觉惯性</em> 模式为例展开介绍。其他的传感器组合和运行模式读者可以参考理解，触类旁通。</p>

<h3 id="系统架构">系统架构</h3>

<p>下图是算法整体的一个pipeline，可以看到一共分为了四个部分：</p>

<ul>
  <li>Tracking: 也就是跟踪，其输入是 <strong>图像帧</strong> 和 <strong>IMU帧</strong>，目的是得到当前帧相对于上一（关键）帧的相对位姿，如果我们知道了第一个（关键）帧的位姿，那么从前往后我们便可以一帧一帧串起来，得到当前帧在世界坐标系中的绝对位姿。</li>
  <li>Local Mapping: 得到当前帧相对于上一帧（参考帧）的相对位姿之后我们便可以通过三角化计算出当前帧视觉特征点的位置，如果当前帧检测出来了1000个特征点，那么局部地（从当前帧往前追溯一直到没有断掉为止），我们便得到了一张具有1000个特征点的地图。</li>
  <li>Loop &amp; Map Merging：即回环检测和地图合并。Local Mapping 毕竟是一个局部地图，如果我们在 Tracking 的时候突然丢失了怎么办？ORBSLAM3的做法是再建立一个局部的地图。而这些局部地图的合集，我们称作 Atlas，翻译为中文就是“地图册”。当运行一段时间之后，如果我们发现又回到了之前到过的地方（回环检测），便可以将之前的局部地图和目前的局部地图进行合并，得到一张更大、特征点更多的地图。</li>
  <li>Full BA：最后便是将位姿和特征点坐标进行联合优化，期待能够得到更加准确的位姿估计和更加准确的特征点地图。</li>
</ul>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/orbslam3-all-in-one/fig1-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/orbslam3-all-in-one/fig1-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/orbslam3-all-in-one/fig1-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/orbslam3-all-in-one/fig1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 1
</div>

<h2 id="算法详解">算法详解</h2>

<h3 id="名词概念">名词概念</h3>

<ul>
  <li>帧 (Frame)</li>
</ul>

<p>帧 (Frame) 可以简单地理解为采集到视频流的每一帧图像。</p>

<ul>
  <li>关键帧 (Key Farme)</li>
</ul>

<p>关键帧 (Key Frame) 是帧 (Frame) 的一个子集，一般情况下是真子集。使用基于关键帧的视觉 SLAM 方法会仅使用一小部分图像帧来估计地图，丢弃掉冗余的信息，降低系统的复杂度。具体来说，当系统检测到场景中出现了显著的运动时，就会将当前图像帧作为一个新的关键帧，并用它来更新地图和计算相机的位姿。</p>

<p>关键帧的作用主要有以下几个方面：</p>

<ol>
  <li>
    <p>建图：通过对不同关键帧的匹配，可以在三维空间中重建场景，从而得到一个稠密的点云地图。</p>
  </li>
  <li>
    <p>定位：当相机在新的位置进行拍摄时，系统可以通过匹配当前帧与已有的关键帧，来估计相机的位姿和当前位置。</p>
  </li>
  <li>
    <p>优化：关键帧可以用于优化相机位姿和地图，从而提高系统的精度和稳定性。</p>
  </li>
</ol>

<p>总之，关键帧是视觉SLAM系统中的重要组成部分，它能够为后续的建图和定位提供重要的信息，从而实现更加准确和可靠的定位和建图。</p>

<ul>
  <li>地图点 (Map Point) 与 地图 (Map)</li>
</ul>

<p>地图点 (Map Point) 是指在三维空间中被重建出来的具有代表性的特征点，并且通过特征匹配算法来识别和跟踪这些特征点，它们对应于场景中的真实物体或者场景结构的点。而地图 (Map) 则是由这些地图点构成的三维点云地图，它记录了场景中物体的位置和姿态信息。地图点和地图之间的关系是非常密切的，地图点是构成地图的基本元素，地图则是地图点的集合。在建立地图的过程中，ORB-SLAM3算法通过将每个图像帧与前面的关键帧匹配，然后通过三角化算法将匹配到的ORB特征点转化为地图点，从而逐渐构建出三维地图。地图点的数量和分布对地图的质量和精度有着重要的影响。</p>

<ul>
  <li>地图册 (Atlas)</li>
</ul>

<p>地图册 (Atlas) 内包含了多个地图，系统内会始终存在一个活跃的地图和一些不活跃的地图，地图之间是不连通的，而每个地图描述了一个联通的局部区域，并包含了该区域的关键帧、地图点以及它们之间的约束信息。跟踪线程不断估计到来的关键帧位姿，并将关键帧插入到当前活跃的地图，并持续优化关键帧的位姿，局部建图线程会持续扩充当前活跃地图。系统还构建了一个唯一的 DBoW2 关键帧数据库，用于重定位、回环检测和地图合并。</p>

<p>Atlas的主要作用是管理和优化大规模地图，因为ORB-SLAM3可以将地图分解为多个局部地图，并在这些局部地图之间建立约束关系，从而实现了地图的高效管理和优化。在定位时，ORB-SLAM3可以利用Atlas中的约束信息来提高定位的精度和鲁棒性。</p>

<ul>
  <li>共视图 (Covisibility Graph)</li>
</ul>

<p>共视图 (Covisibility Graph) 表达了关键帧之间的关系。共视图中的节点为关键帧，如果两个节点（关键帧）之间有足够的共视关系，即他们能够同时观测到一些相同的地图点，则这两个节点之间存在一条边，边的权重为两个关键帧中共同观测到的地图点数量。在局部地图优化中，ORB-SLAM3 选择与当前关键帧具有很强共视关系的关键帧进行优化；在回环检测中，也会利用与当前关键帧具有很强共视关系的关键帧来确定是否存在回环。</p>

<ul>
  <li>生成树 (Spanning Tree)</li>
</ul>

<p>在图论中，一个连通图的生成树是该图的一个极小连通子图，它包含图中所有的 n 个节点，但只构成一棵树的 n-1 条边。ORB-SLAM3 中的生成树 (Spanning Tree) 便是共视图的一个生成树。生成树的目的是将共视图中所有的关键帧连接成一颗树，以减少地图优化和回环检测的计算复杂度。由于共视图中的所有关键帧之间都有一定程度的视觉重叠，因此直接使用共视图进行地图优化和回环检测会导致大量冗余计算。而生成树则可以使计算集中在树形结构中，避免冗余计算。</p>

<ul>
  <li>本质图 (Essential Graph)</li>
</ul>

<p>本质图 (Essential Graph) 的概念在 ORB-SLAM3 中被一笔带过，我们可以通过最初版本的 ORB-SLAM 中找到相关的介绍：</p>

<blockquote>
  <p>In order to correct a loop we perform a pose graph optimization that distributes the loop closing error along the graph. In order not to include all the edges provided by the covisibility graph, which can be very dense, we propose to build an Essential Graph that retains all the nodes (keyframes), but less edges, still preserving a strong network that yields accurate results. The system builds incrementally a spanning tree from the initial keyframe, which provides a connected subgraph of the covisibility graph with minimal number of edges. When a new keyframe is inserted, it is included in the tree linked to the keyframe which shares most point observations, and when a keyframe is erased by the culling policy, the system updates the links affected by that keyframe. The Essential Graph contains the spanning tree, the subset of edges from the covisibility graph with high covisibility (min = 100), and the loop closure edges, resulting in a strong network of cameras.</p>
</blockquote>

<p>也就是说，由于共视图的边太过稠密，给优化带来了不小的麻烦，而本质图的节点和共视图保持一致，但是拥有更少的边，并且在本质图上进行优化也能够提供足够精确的结果。新的关键帧会在生成树中被链接到与它拥有最多共视关系的关键帧上，而当该关键帧被删除时，也会在生成树中删掉与该关键帧的链接关系。本质图中的边保留了共视图中权重（共视关系）大于一定阈值的边，并在此基础上加入了回环边。</p>

<p>下图给出了关键帧、共视图、生成树和本质图之间的关系。可以看出，共视图最稠密，本质图次之，生成树最稀疏。</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/orbslam3-all-in-one/fig2-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/orbslam3-all-in-one/fig2-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/orbslam3-all-in-one/fig2-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/orbslam3-all-in-one/fig2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 2
</div>

<h3 id="跟踪">跟踪</h3>

<center>
<div class="jekyll-diagrams diagrams mermaid">
  Rendering Failed: mmdc --puppeteerConfigFile /home/runner/work/renwuli.github.io/renwuli.github.io/vendor/bundle/ruby/3.2.0/gems/jekyll-diagrams-0.10.0/vendor/mermaid_puppeteer_config.json --input /tmp/input20230426-1791-rp69iv --output /tmp/output20230426-1791-71ne9y.svg: node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

Error: Evaluation failed: Error: Parse error on line 1:
---title: 初始化---f
^
Expecting 'NEWLINE', 'SPACE', 'GRAPH', got 'ARROW_OPEN'
    at Yt.parseError (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:486512)
    at Yt.parse (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:487678)
    at Object.e.getClasses (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:749437)
    at Object.render (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:759998)
    at s (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:8:233)
    at Object.init (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:8:318)
    at __puppeteer_evaluation_script__:17:20
    at ExecutionContext._evaluateInternal (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/ExecutionContext.js:122:13)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async ExecutionContext.evaluate (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/ExecutionContext.js:48:12)
    at async ElementHandle.evaluate (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:55:12)
    at async ElementHandle.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:478:20)
  -- ASYNC --
    at ExecutionContext.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:111:15)
    at ElementHandle.evaluate (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:55:42)
    at ElementHandle.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:112:23)
    at ElementHandle.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:478:40)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
  -- ASYNC --
    at ElementHandle.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:111:15)
    at DOMWorld.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/DOMWorld.js:156:21)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
  -- ASYNC --
    at Frame.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:111:15)
    at Page.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/Page.js:347:29)
    at Page.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:112:23)
    at /usr/local/lib/node_modules/mermaid.cli/index.bundle.js:83:14
    at Generator.next (<anonymous>)
    at step (/usr/local/lib/node_modules/mermaid.cli/index.bundle.js:4:191)
    at /usr/local/lib/node_modules/mermaid.cli/index.bundle.js:4:361
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)

Node.js v18.16.0


&lt;/div&gt;

&lt;/center&gt;


如上图所示跟踪线程大体上包括三个主要部分：
1. 初始化
2. 跟踪：跟踪又主要包括从上一（关键）帧到当前帧的位姿跟踪，和当前帧与局部地图之间的跟踪
3. 记录位姿信息：跟踪并优化得到当前帧的位姿之后，记录下来

上面流程图的重要模块的主要内容和流程分别如下所示：

- 初始化

<center>
<div class="jekyll-diagrams diagrams mermaid">
  Rendering Failed: mmdc --puppeteerConfigFile /home/runner/work/renwuli.github.io/renwuli.github.io/vendor/bundle/ruby/3.2.0/gems/jekyll-diagrams-0.10.0/vendor/mermaid_puppeteer_config.json --input /tmp/input20230426-1791-2sjvt7 --output /tmp/output20230426-1791-fw1ooo.svg: node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

Error: Evaluation failed: Error: Parse error on line 1:
---title: 初始化---f
^
Expecting 'NEWLINE', 'SPACE', 'GRAPH', got 'ARROW_OPEN'
    at Yt.parseError (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:486512)
    at Yt.parse (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:487678)
    at Object.e.getClasses (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:749437)
    at Object.render (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:759998)
    at s (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:8:233)
    at Object.init (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:8:318)
    at __puppeteer_evaluation_script__:17:20
    at ExecutionContext._evaluateInternal (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/ExecutionContext.js:122:13)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async ExecutionContext.evaluate (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/ExecutionContext.js:48:12)
    at async ElementHandle.evaluate (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:55:12)
    at async ElementHandle.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:478:20)
  -- ASYNC --
    at ExecutionContext.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:111:15)
    at ElementHandle.evaluate (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:55:42)
    at ElementHandle.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:112:23)
    at ElementHandle.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:478:40)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
  -- ASYNC --
    at ElementHandle.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:111:15)
    at DOMWorld.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/DOMWorld.js:156:21)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
  -- ASYNC --
    at Frame.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:111:15)
    at Page.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/Page.js:347:29)
    at Page.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:112:23)
    at /usr/local/lib/node_modules/mermaid.cli/index.bundle.js:83:14
    at Generator.next (<anonymous>)
    at step (/usr/local/lib/node_modules/mermaid.cli/index.bundle.js:4:191)
    at /usr/local/lib/node_modules/mermaid.cli/index.bundle.js:4:361
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)

Node.js v18.16.0


&lt;/div&gt;

&lt;/center&gt;

- 恒速模型跟踪

<center>
<div class="jekyll-diagrams diagrams mermaid">
  Rendering Failed: mmdc --puppeteerConfigFile /home/runner/work/renwuli.github.io/renwuli.github.io/vendor/bundle/ruby/3.2.0/gems/jekyll-diagrams-0.10.0/vendor/mermaid_puppeteer_config.json --input /tmp/input20230426-1791-d6ug4k --output /tmp/output20230426-1791-5vc36c.svg: node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

Error: Evaluation failed: Error: Parse error on line 1:
---title: 恒速模型跟踪--
^
Expecting 'NEWLINE', 'SPACE', 'GRAPH', got 'ARROW_OPEN'
    at Yt.parseError (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:486512)
    at Yt.parse (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:487678)
    at Object.e.getClasses (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:749437)
    at Object.render (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:759998)
    at s (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:8:233)
    at Object.init (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:8:318)
    at __puppeteer_evaluation_script__:17:20
    at ExecutionContext._evaluateInternal (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/ExecutionContext.js:122:13)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async ExecutionContext.evaluate (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/ExecutionContext.js:48:12)
    at async ElementHandle.evaluate (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:55:12)
    at async ElementHandle.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:478:20)
  -- ASYNC --
    at ExecutionContext.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:111:15)
    at ElementHandle.evaluate (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:55:42)
    at ElementHandle.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:112:23)
    at ElementHandle.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:478:40)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
  -- ASYNC --
    at ElementHandle.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:111:15)
    at DOMWorld.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/DOMWorld.js:156:21)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
  -- ASYNC --
    at Frame.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:111:15)
    at Page.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/Page.js:347:29)
    at Page.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:112:23)
    at /usr/local/lib/node_modules/mermaid.cli/index.bundle.js:83:14
    at Generator.next (<anonymous>)
    at step (/usr/local/lib/node_modules/mermaid.cli/index.bundle.js:4:191)
    at /usr/local/lib/node_modules/mermaid.cli/index.bundle.js:4:361
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)

Node.js v18.16.0


&lt;/div&gt;

&lt;/center&gt;

- 参考关键帧跟踪

<center>
<div class="jekyll-diagrams diagrams mermaid">
  Rendering Failed: mmdc --puppeteerConfigFile /home/runner/work/renwuli.github.io/renwuli.github.io/vendor/bundle/ruby/3.2.0/gems/jekyll-diagrams-0.10.0/vendor/mermaid_puppeteer_config.json --input /tmp/input20230426-1791-sztqpl --output /tmp/output20230426-1791-hktn8x.svg: node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

Error: Evaluation failed: Error: Parse error on line 1:
---title: 参考关键帧跟踪-
^
Expecting 'NEWLINE', 'SPACE', 'GRAPH', got 'ARROW_OPEN'
    at Yt.parseError (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:486512)
    at Yt.parse (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:487678)
    at Object.e.getClasses (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:749437)
    at Object.render (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:759998)
    at s (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:8:233)
    at Object.init (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:8:318)
    at __puppeteer_evaluation_script__:17:20
    at ExecutionContext._evaluateInternal (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/ExecutionContext.js:122:13)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async ExecutionContext.evaluate (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/ExecutionContext.js:48:12)
    at async ElementHandle.evaluate (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:55:12)
    at async ElementHandle.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:478:20)
  -- ASYNC --
    at ExecutionContext.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:111:15)
    at ElementHandle.evaluate (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:55:42)
    at ElementHandle.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:112:23)
    at ElementHandle.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:478:40)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
  -- ASYNC --
    at ElementHandle.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:111:15)
    at DOMWorld.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/DOMWorld.js:156:21)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
  -- ASYNC --
    at Frame.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:111:15)
    at Page.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/Page.js:347:29)
    at Page.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:112:23)
    at /usr/local/lib/node_modules/mermaid.cli/index.bundle.js:83:14
    at Generator.next (<anonymous>)
    at step (/usr/local/lib/node_modules/mermaid.cli/index.bundle.js:4:191)
    at /usr/local/lib/node_modules/mermaid.cli/index.bundle.js:4:361
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)

Node.js v18.16.0


&lt;/div&gt;

&lt;/center&gt;

- 局部地图跟踪

<center>
<div class="jekyll-diagrams diagrams mermaid">
  Rendering Failed: mmdc --puppeteerConfigFile /home/runner/work/renwuli.github.io/renwuli.github.io/vendor/bundle/ruby/3.2.0/gems/jekyll-diagrams-0.10.0/vendor/mermaid_puppeteer_config.json --input /tmp/input20230426-1791-l8liao --output /tmp/output20230426-1791-y941n8.svg: node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

Error: Evaluation failed: Error: Parse error on line 1:
---title: 局部地图跟踪--
^
Expecting 'NEWLINE', 'SPACE', 'GRAPH', got 'ARROW_OPEN'
    at Yt.parseError (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:486512)
    at Yt.parse (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:487678)
    at Object.e.getClasses (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:749437)
    at Object.render (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:759998)
    at s (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:8:233)
    at Object.init (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:8:318)
    at __puppeteer_evaluation_script__:17:20
    at ExecutionContext._evaluateInternal (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/ExecutionContext.js:122:13)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async ExecutionContext.evaluate (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/ExecutionContext.js:48:12)
    at async ElementHandle.evaluate (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:55:12)
    at async ElementHandle.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:478:20)
  -- ASYNC --
    at ExecutionContext.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:111:15)
    at ElementHandle.evaluate (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:55:42)
    at ElementHandle.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:112:23)
    at ElementHandle.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:478:40)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
  -- ASYNC --
    at ElementHandle.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:111:15)
    at DOMWorld.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/DOMWorld.js:156:21)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
  -- ASYNC --
    at Frame.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:111:15)
    at Page.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/Page.js:347:29)
    at Page.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:112:23)
    at /usr/local/lib/node_modules/mermaid.cli/index.bundle.js:83:14
    at Generator.next (<anonymous>)
    at step (/usr/local/lib/node_modules/mermaid.cli/index.bundle.js:4:191)
    at /usr/local/lib/node_modules/mermaid.cli/index.bundle.js:4:361
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)

Node.js v18.16.0


&lt;/div&gt;

&lt;/center&gt;

- 判断当前帧是否为关键帧


<center>
<div class="jekyll-diagrams diagrams mermaid">
  Rendering Failed: mmdc --puppeteerConfigFile /home/runner/work/renwuli.github.io/renwuli.github.io/vendor/bundle/ruby/3.2.0/gems/jekyll-diagrams-0.10.0/vendor/mermaid_puppeteer_config.json --input /tmp/input20230426-1791-2wje4r --output /tmp/output20230426-1791-lkm6us.svg: node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

Error: Evaluation failed: Error: Parse error on line 1:
---title: 判断当前帧是否为关
^
Expecting 'NEWLINE', 'SPACE', 'GRAPH', got 'ARROW_OPEN'
    at Yt.parseError (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:486512)
    at Yt.parse (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:487678)
    at Object.e.getClasses (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:749437)
    at Object.render (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:1:759998)
    at s (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:8:233)
    at Object.init (file:///usr/local/lib/node_modules/mermaid.cli/mermaid.min.js:8:318)
    at __puppeteer_evaluation_script__:17:20
    at ExecutionContext._evaluateInternal (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/ExecutionContext.js:122:13)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async ExecutionContext.evaluate (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/ExecutionContext.js:48:12)
    at async ElementHandle.evaluate (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:55:12)
    at async ElementHandle.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:478:20)
  -- ASYNC --
    at ExecutionContext.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:111:15)
    at ElementHandle.evaluate (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:55:42)
    at ElementHandle.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:112:23)
    at ElementHandle.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/JSHandle.js:478:40)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
  -- ASYNC --
    at ElementHandle.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:111:15)
    at DOMWorld.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/DOMWorld.js:156:21)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
  -- ASYNC --
    at Frame.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:111:15)
    at Page.$eval (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/Page.js:347:29)
    at Page.<anonymous> (/usr/local/lib/node_modules/mermaid.cli/node_modules/puppeteer/lib/helper.js:112:23)
    at /usr/local/lib/node_modules/mermaid.cli/index.bundle.js:83:14
    at Generator.next (<anonymous>)
    at step (/usr/local/lib/node_modules/mermaid.cli/index.bundle.js:4:191)
    at /usr/local/lib/node_modules/mermaid.cli/index.bundle.js:4:361
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)

Node.js v18.16.0


&lt;/div&gt;

&lt;/center&gt;

### 局部建图

- 插入新关键帧

- 地图点更新

- 局部 BA

- IMU 初始化

- 局部关键帧剔除

- IMU 尺度优化

### 回环检测与地图合并

- 回环检测
    - 数据库查询
    - 计算相对位姿
    - 本质图优化
    - 回环

- 地图合并
    - 本质图优化
    - BA
    - 合并地图

### 全局优化
</anonymous></anonymous></anonymous></anonymous></anonymous></anonymous></div></center></anonymous></anonymous></anonymous></anonymous></anonymous></anonymous></div></center></anonymous></anonymous></anonymous></anonymous></anonymous></anonymous></div></center></anonymous></anonymous></anonymous></anonymous></anonymous></anonymous></div></center></anonymous></anonymous></anonymous></anonymous></anonymous></anonymous></div></center></anonymous></anonymous></anonymous></anonymous></anonymous></anonymous></div></center>]]></content><author><name></name></author><category term="SLAM" /><category term="ORBSLAM3" /><summary type="html"><![CDATA[Dive into ORBSLAM3]]></summary></entry><entry><title type="html">Wheel Preintegration</title><link href="https://renwuli.github.io/blog/2022/Wheel-Preintegration/" rel="alternate" type="text/html" title="Wheel Preintegration" /><published>2022-11-11T20:00:00+00:00</published><updated>2022-11-11T20:00:00+00:00</updated><id>https://renwuli.github.io/blog/2022/Wheel-Preintegration</id><content type="html" xml:base="https://renwuli.github.io/blog/2022/Wheel-Preintegration/"><![CDATA[<h2 id="轮速计噪声模型">轮速计噪声模型</h2>

\[_{O}\widetilde{\mathbf{u}}(t) = _{O}\mathbf{u}(t) + \mathbf{\eta}^{u}(t)\]

<h2 id="轮速计运动模型">轮速计运动模型</h2>

\[_{W} \dot{\mathbf{o}} = _{W}\mathbf{u}\]

\[_{W} \dot{\mathbf{o}} = \mathrm{R}_{WB} \cdot \mathrm{R}^{B}_{O} \cdot _{O} \mathbf{u}\]

<h2 id="相邻时刻的轮速测量模型">相邻时刻的轮速测量模型</h2>

\[_{W}\mathbf{o}(t + \triangle t) = _{W}\mathbf{o}(t) + _{W}\mathbf{u} (t) \triangle t\]

<p>将 \(\mathrm{R}_{WB}\) 记作 \(\mathrm{R}\)，默认位移 \(\mathbf{o}\) 和速度 \(\mathbf{v}\) 为世界坐标系下的量，则：</p>

\[\mathbf{o}(t + \triangle t) = \mathbf{o}(t) + \mathrm{R}_{k} \cdot \mathrm{R}^{B}_{O} \cdot \mathbf{u} \triangle t\]

<p>考虑噪声模型，有：</p>

\[\mathbf{o}(t + \triangle t) = \mathbf{o}(t) + \mathrm{R}_{k} \cdot \mathrm{R}^{B}_{O} \cdot \left( 
  \tilde{\mathbf{u}}(t) - \mathbf{\eta}^{ud}(t)
 \right) \triangle t\]

<h2 id="关键帧之间的轮速测量模型">关键帧之间的轮速测量模型</h2>

\[\mathbf{o}_{j} = \mathbf{o}_{i} + \sum_{k=i}^{j-1} \mathrm{R}_{k} \cdot \mathrm{R}^{B}_{O} \left( 
  \tilde{\mathbf{u}}_{k} - \mathbf{\eta}^{ud}_{k}
 \right) \triangle t\]

<h2 id="预积分">预积分</h2>

<p>将第 \(i\) 时刻的状态分离出来：</p>

\[\mathbf{o}_{j} - \mathbf{o}_{i} = \sum_{k=i}^{j-1} \mathrm{R}_{k} \cdot \mathrm{R}^{B}_{O} \left( 
  \tilde{\mathbf{u}}_{k} - \mathbf{\eta}^{ud}_{k}
 \right) \triangle t\]

<p>并转换到第 \(i\) 时刻的IMU坐标系，得：</p>

\[\begin{align*}
\triangle \mathbf{o}_{ij} &amp;= \mathrm{R}_{i}^{T} \left( \mathbf{o}_{j} - \mathbf{o}_{i} \right) \\
&amp;= \sum_{k=i}^{j-1} \triangle  \mathrm{R}_{ik} \cdot \mathrm{R}^{B}_{O} \left( 
  \tilde{\mathbf{u}}_{k} - \mathbf{\eta}^{ud}_{k}
 \right) \triangle t
\end{align*}\]

\[{\color{red}
\triangle \mathbf{o}_{ij} = \mathrm{R}_{i}^{T} \left( \mathbf{p}_{j} - \mathbf{p}_{i} \right) - \mathbf{t}_{O}^{B} + \mathrm{R}_{i}^{T} \mathrm{R}_{j} \mathbf{t}_{O}^{B}
}\]

<h3 id="分离噪声">分离噪声</h3>

<p>将上述预积分公式中得噪声分离出来：</p>

\[\begin{align*}
  \triangle \mathbf{o}_{ij} &amp;= \sum_{k=i}^{j-1} \triangle \mathrm{R}_{ik} \cdot \mathrm{R}^{B}_{O} \left( 
  \tilde{\mathbf{u}}_{k} - \mathbf{\eta}^{ud}_{k}
 \right) \triangle t \\
&amp;= \sum_{k=i}^{j-1} \triangle \tilde{\mathrm{R}}_{ik} \left( 
  \mathbf{I} - \delta\phi_{ik}^{\wedge} \right) \mathrm{R}^{B}_{O} \tilde{\mathbf{u}}_{k} \triangle t
   - \triangle  \tilde{\mathrm{R}}_{ik} \mathrm{R}^{B}_{O} \mathbf{\eta}_{k}^{ud} \triangle t \\
&amp;= \sum_{k=i}^{j-1} \triangle \tilde{\mathrm{R}}_{ik} \mathrm{R}^{B}_{O} \tilde{\mathbf{u}}_{k} \triangle t + \sum_{k=i}^{j-1} \left[ 
  \triangle \tilde{\mathrm{R}}_{ik} \left( 
     \mathrm{R}^{B}_{O} \tilde{\mathbf{u}}_{k}
   \right)^{\wedge} \delta \phi_{ik} \triangle t - \triangle \tilde{\mathrm{R}}_{ik} \mathrm{R}^{B}_{O} \mathbf{\eta}_{k}^{ud} \triangle t
 \right] \\ 
&amp;= \triangle \tilde{\mathbf{o}}_{ij} - \delta \mathbf{o}_{ij}
\end{align*}\]

<p>其中：</p>

\[\begin{align*}
\triangle \tilde{\mathbf{o}}_{ij} &amp;= \sum_{k=i}^{j-1} \triangle \tilde{\mathrm{R}}_{ik} \mathrm{R}^{B}_{O} \tilde{\mathbf{u}}_{k} \triangle t \\
&amp;= \triangle \mathbf{o}_{ij} + \delta \mathbf{o}_{ij}
\end{align*}\]

<h3 id="噪声传播">噪声传播</h3>

\[\begin{align*}
 \delta \mathbf{o}_{ij} &amp;= \sum_{k=i}^{j-1} \left[ 
  -\triangle \tilde{\mathrm{R}}_{ik} \left( 
     \mathrm{R}^{B}_{O} \tilde{\mathbf{u}}_{k}
   \right)^{\wedge} \delta \phi_{ik} \triangle t + \triangle \tilde{\mathrm{R}}_{ik} \mathrm{R}^{B}_{O} \mathbf{\eta}_{k}^{ud} \triangle t
 \right] \\
&amp;= \sum_{k=i}^{j-2} \left[
  -\triangle \tilde{\mathrm{R}}_{ik} \left( 
     \mathrm{R}^{B}_{O} \tilde{\mathbf{u}}_{k}
   \right)^{\wedge} \delta \phi_{ik} \triangle t + \triangle \tilde{\mathrm{R}}_{ik} \mathbf{\eta}_{k}^{ud} \mathrm{R}^{B}_{O} \triangle t
 \right] \\
&amp;- \triangle \tilde{\mathrm{R}}_{ij-1} \left( 
     \mathrm{R}^{B}_{O} \tilde{\mathbf{u}}_{j-1}
   \right)^{\wedge} \delta \phi_{ij-1} \triangle t + \triangle \tilde{\mathrm{R}}_{ij-1} \mathrm{R}^{B}_{O} \mathbf{\eta}_{j-1}^{ud} \triangle t \\
&amp;= \delta \mathbf{o}_{ij-1} - \triangle \tilde{\mathrm{R}}_{ij-1} \left( 
     \mathrm{R}^{B}_{O} \tilde{\mathbf{u}}_{j-1}
   \right)^{\wedge} \delta \phi_{ij-1} \triangle t + \triangle \tilde{\mathrm{R}}_{ij-1} \mathrm{R}^{B}_{O} \mathbf{\eta}_{j-1}^{ud} \triangle t
\end{align*}\]

<p>令预积分的噪声向量为:</p>

\[\delta \mathbf{\eta}_{ik}^{\triangle} = \left[ \delta \mathbf{\phi}_{ik}, \delta \mathbf{v}_{ik}, \delta \mathbf{p}_{ik}, \delta \mathbf{o}_{ik} \right] \in \mathbb{R}^{12}\]

<p>传感器噪声为：</p>

\[\mathbf{\eta}_{k}^{d} = \left[ \mathbf{\eta}_{k}^{gd}, \mathbf{\eta}_{k}^{ad}, \mathbf{\eta}_{k}^{ud} \right] \in \mathbb{R}^{3 \times 3} =  \in \mathbb{R}^{9}\]

<p>则预积分噪声的递推公式为：</p>

\[\delta \mathbf{\eta}_{ij}^{\triangle} = \mathbf{A}_{j-1} \delta \mathbf{\eta}_{ij-1}^{\triangle} + \mathbf{B}_{j-1} \mathbf{\eta}_{j-1}^{d}\]

<p>则：</p>

\[\mathbf{A}_{j-1} = \begin{bmatrix}
  \triangle \tilde{\mathrm{R}}_{j-1 j}^{T} &amp; 0 &amp; 0 &amp; 0 \\
  -\triangle \tilde{\mathrm{R}}_{i j-1} \left( \tilde{\mathbf{a}}_{j-1} - \mathbf{b}_{i}^{a} \right)^{\wedge} \triangle t &amp; \mathbf{I} &amp; 0 &amp; 0 \\
  -\frac{1}{2} \triangle \tilde{\mathrm{R}}_{i j-1} \left( \tilde{\mathbf{a}}_{j-1} - \mathbf{b}_{i}^{a} \right)^{\wedge} \triangle t^{2} &amp; \triangle t \mathbf{I} &amp; 0 &amp; 0 \\
  -\triangle \tilde{\mathrm{R}}_{ij-1} \left( 
     \mathrm{R}^{B}_{O} \tilde{\mathbf{u}}_{j-1}
   \right)^{\wedge} \triangle t &amp; 0 &amp; 0 &amp; 0
\end{bmatrix}  \in \mathbb{R}^{12 \times 12}\]

\[\mathbf{B}_{j-1} = \begin{bmatrix}
  \mathbf{J}_{r}^{j-1} \triangle t &amp; 0 &amp; 0 \\
  0 &amp; \triangle \tilde{\mathrm{R}}_{i j-1} \triangle t &amp; 0 \\
  0 &amp; \frac{1}{2}  \triangle \tilde{\mathrm{R}}_{i j-1} \triangle t^{2} &amp; 0 \\
  0 &amp; 0 &amp; \triangle \tilde{\mathrm{R}}_{i j-1} \mathrm{R}^{B}_{O} \triangle t
\end{bmatrix}  \in \mathbb{R}^{12 \times 9}\]

<p>协方差矩阵递推公式为：</p>

\[\mathbf{\Sigma}_{ij} = \mathbf{A}_{j-1} \mathbf{\Sigma}_{ij-1} \mathbf{A}_{j-1}^{T} + \mathbf{B}_{j-1} \mathbf{\Sigma}_{\mathbf{\eta}}\mathbf{B}_{j-1}^{T}  \in \mathbb{R}^{12 \times 12}\]

\[\mathbf{\Sigma}_{\mathbf{\eta}} \in \mathbb{R}^{9 \times 9}\]

<h3 id="偏置更新">偏置更新</h3>

\[\triangle \tilde{\mathbf{o}}_{ij} \left( \mathbf{b}_{i}^{g} \right) \simeq \triangle \tilde{\mathbf{o}}_{ij} \left( \bar{\mathbf{b}}_{i}^{g} \right) + \frac{\partial{\bar{\mathbf{o}}_{ij}}}{\partial{\mathbf{b}_{i}^{g}}} \delta \mathbf{b}_{i}^{g}\]

<p>其中：</p>

\[\bar{\mathbf{o}}_{ij} = \tilde{\mathbf{o}}_{ij} \left( \bar{\mathbf{b}}_{i} \right)\]

<p>当偏置进行更新：</p>

\[\hat{\mathbf{b}}_{i} \leftarrow \bar{\mathbf{b}}_{i} + \delta \mathbf{b}_{i}\]

<p>相应的预积分进行更新：</p>

\[\begin{align*}
\tilde{\mathbf{o}}_{ij} (\hat{\mathbf{b}}_{i}) &amp;= \sum_{k=i}^{j-1} \triangle \tilde{\mathrm{R}}_{ik} (\hat{\mathbf{b}}_{i}) \mathrm{R}^{B}_{O} \tilde{\mathbf{u}}_{k} \triangle t \\
&amp;= \sum_{k=i}^{j-1} \triangle \bar{\mathrm{R}}_{ik} \mathbf{Exp} \left( \frac{\partial{\triangle \bar{\mathrm{R}}_{ik}}}{\partial{\mathbf{b}^{g}}} \delta \mathbf{b}_{i}^{g} \right) \mathrm{R}^{B}_{O} \tilde{\mathbf{u}}_{k} \triangle t \\
&amp;= \sum_{k=i}^{j-1} \triangle \bar{\mathrm{R}}_{ik} \left( 
  \mathbf{I} + \left( 
    \frac{\partial{\triangle \bar{\mathrm{R}}_{ik}}}{\partial{\mathbf{b}^{g}}} \delta \mathbf{b}_{i}^{g}
   \right)^{\wedge}
 \right) \mathrm{R}^{B}_{O} \tilde{\mathbf{u}}_{k} \triangle t \\
&amp;= \sum_{k=i}^{j-1} \triangle \bar{\mathrm{R}}_{ik} \mathrm{R}^{B}_{O} \tilde{\mathbf{u}}_{k} \triangle t + \sum_{k=i}^{j-1} \triangle  \bar{\mathrm{R}}_{ik} \left( 
    \frac{\partial{\triangle \bar{\mathrm{R}}_{ik}}}{\partial{\mathbf{b}^{g}}} \delta \mathbf{b}_{i}^{g}
   \right)^{\wedge} \mathrm{R}^{B}_{O} \tilde{\mathbf{u}}_{k} \triangle t \\
&amp;= \triangle \bar{\mathbf{o}}_{ij} + \sum_{k=i}^{j-1} \triangle \bar{\mathrm{R}}_{ik} \left( 
    \frac{\partial{\triangle \bar{\mathrm{R}}_{ik}}}{\partial{\mathbf{b}^{g}}} \delta \mathbf{b}_{i}^{g}
   \right)^{\wedge} \left( \mathrm{R}^{B}_{O} \tilde{\mathbf{u}}_{k} \right) \triangle t \\
&amp;= \triangle \bar{\mathbf{o}}_{ij} - \sum_{k=i}^{j-1} \triangle \bar{\mathrm{R}}_{ik} \left( \mathrm{R}^{B}_{O} \tilde{\mathbf{u}}_{k} \right)^{\wedge} \left( 
    \frac{\partial{\triangle \bar{\mathrm{R}}_{ik}}}{\partial{\mathbf{b}^{g}}} \delta \mathbf{b}_{i}^{g}
   \right) \triangle t \\
&amp;= \triangle \bar{\mathbf{o}}_{ij} - \sum_{k=i}^{j-1} \triangle \bar{\mathrm{R}}_{ik} \left( \mathrm{R}^{B}_{O} \tilde{\mathbf{u}}_{k} \right)^{\wedge} 
    \frac{\partial{\triangle \bar{\mathrm{R}}_{ik}}}{\partial{\mathbf{b}^{g}}} \triangle t  \cdot \delta \mathbf{b}_{i}^{g} \\
&amp;= {\color{red} \triangle \bar{\mathbf{o}}_{ij} + \frac{\partial{\triangle \bar{\mathbf{o}}_{ij}}}{\partial{\mathbf{b}^{g}}} \delta \mathbf{b}_{i}^{g}}
\end{align*}\]

<p>所以：</p>

\[\frac{\partial{\triangle \bar{\mathbf{o}}_{ij}}}{\partial{\mathbf{b}^{g}}} = - \sum_{k=i}^{j-1} \triangle \bar{\mathrm{R}}_{ik} \left( \mathrm{R}^{B}_{O} \tilde{\mathbf{u}}_{k} \right)^{\wedge} 
    \frac{\partial{\triangle \bar{\mathrm{R}}_{ik}}}{\partial{\mathbf{b}^{g}}} \triangle t\]

<h3 id="预积分残差项">预积分残差项</h3>

\[\begin{align*}
\mathbf{r}_{\triangle \mathbf{o}_{ij}} &amp;= \mathrm{R}_{i}^{T} \left( \mathbf{p}_{j} - \mathbf{p}_{i} \right) - \mathbf{t}_{O}^{B} + \mathrm{R}_{i}^{T} \mathrm{R}_{j} \mathbf{t}_{O}^{B} \\
&amp;- \left( \triangle \tilde{\mathbf{o}}_{ij} \left( \bar{\mathbf{b}}_{i}^{g} \right) + \frac{\partial{\bar{\mathbf{o}}_{ij}}}{\partial{\mathbf{b}_{i}^{g}}} \delta \mathbf{b}_{i}^{g} \right)  \\
&amp;= \mathrm{R}_{i}^{T} \left( \mathbf{p}_{j} - \mathbf{p}_{i} \right) - \mathbf{t}_{O}^{B} + \mathrm{R}_{i}^{T} \mathrm{R}_{j} \mathbf{t}_{O}^{B} \\
&amp;- \left( \triangle \bar{\mathbf{o}}_{ij} + \frac{\partial{\bar{\mathbf{o}}_{ij}}}{\partial{\mathbf{b}_{i}^{g}}} \delta \mathbf{b}_{i}^{g} \right) 
\end{align*}\]

<h4 id="雅各比求解">雅各比求解</h4>

\[\begin{array}{l}
\mathrm{R}_{i} \leftarrow \mathrm{R}_{i} \operatorname{Exp}\left(\delta \boldsymbol{\phi}_{i}\right), \quad \mathrm{R}_{j} \leftarrow \mathrm{R}_{j} \operatorname{Exp}\left(\delta \boldsymbol{\phi}_{j}\right) \\[2mm]
\mathbf{p}_{i} \leftarrow \mathbf{p}_{i}+\mathrm{R}_{i} \delta \mathbf{p}_{i}, \quad \mathbf{p}_{j} \leftarrow \mathbf{p}_{j}+\mathrm{R}_{j} \delta \mathbf{p}_{j} \\[2mm]
\mathbf{v}_{i} \leftarrow \mathbf{v}_{i}+\delta \mathbf{v}_{i}, \quad \mathbf{v}_{j} \leftarrow \mathbf{v}_{j}+\delta \mathbf{v}_{i} \\[2mm]
\delta \mathbf{b}_{i}^{g} \leftarrow \delta \mathbf{b}_{i}^{g}+\tilde{\delta} \mathbf{b}_{i}^{g}, \quad \delta \mathbf{b}_{i}^{a} \leftarrow \delta \mathbf{b}_{i}^{a}+\tilde{\delta} \mathbf{b}_{i}^{a} \\
\end{array}\]

<ul>
  <li>对 \(\delta \mathbf{p}_{i}\)</li>
</ul>

\[\begin{align*}
\mathbf{r}_{\triangle \mathbf{o}_{ij}} (\mathbf{p}_{i} + \mathrm{R}_{i} \delta \mathbf{p}_{i}) &amp;= \mathrm{R}_{i}^{T} \left( \mathbf{p}_{j} - \mathbf{p}_{i} - \mathrm{R}_{i} \delta \mathbf{p}_{i} \right) - \mathbf{t}_{O}^{B} + \mathrm{R}_{i}^{T} \mathrm{R}_{j} \mathbf{t}_{O}^{B} + C \\
&amp;= \mathrm{R}_{i}^{T} \left( \mathbf{p}_{j} - \mathbf{p}_{i} \right) - \mathbf{t}_{O}^{B} + \mathrm{R}_{i}^{T} \mathrm{R}_{j} \mathbf{t}_{O}^{B} + C - \delta \mathbf{p}_{i} \\
&amp;= \mathbf{r}_{\triangle \mathbf{o}_{ij}} (\mathbf{p}_{i}) + (-\mathbf{I}_{3 \times 1}) \delta \mathbf{p}_{i}
\end{align*}\]

<p>所以：</p>

\[\frac{\partial{\mathbf{r}_{\triangle \mathbf{o}_{ij}}}}{\partial{\delta \mathbf{p}_{i}}} = -\mathbf{I}_{3 \times 1}\]

<ul>
  <li>对 \(\delta \mathbf{p}_{j}\)</li>
</ul>

\[\begin{align*}
\mathbf{r}_{\triangle \mathbf{o}_{ij}} (\mathbf{p}_{j} + \mathrm{R}_{j} \delta \mathbf{p}_{j}) &amp;= \mathrm{R}_{i}^{T} \left( \mathbf{p}_{j} + \mathrm{R}_{j} \delta \mathbf{p}_{j} - \mathbf{p}_{i} \right) - \mathbf{t}_{O}^{B} + \mathrm{R}_{i}^{T} \mathrm{R}_{j} \mathbf{t}_{O}^{B} + C \\
&amp;= \mathrm{R}_{i}^{T} \left( \mathbf{p}_{j} - \mathbf{p}_{i} \right) - \mathbf{t}_{O}^{B} + \mathrm{R}_{i}^{T} \mathrm{R}_{j} \mathbf{t}_{O}^{B} + C + (\mathrm{R}_{i}^{T} \mathrm{R}_{j}) \delta \mathbf{p}_{j} \\
&amp;= \mathbf{r}_{\triangle \mathbf{o}_{ij}} (\mathbf{p}_{i}) + (\mathrm{R}_{i}^{T} \mathrm{R}_{j}) \delta \mathbf{p}_{i}
\end{align*}\]

<p>所以：</p>

\[\frac{\partial{\mathbf{r}_{\triangle \mathbf{o}_{ij}}}}{\partial{\delta \mathbf{p}_{i}}} = \mathrm{R}_{i}^{T} \mathrm{R}_{j}\]

<ul>
  <li>对 \(\delta \mathbf{v}_{i}\)</li>
</ul>

\[\frac{\partial{\mathbf{r}_{\triangle \mathbf{o}_{ij}}}}{\partial{\delta \mathbf{v}_{i}}} = 0\]

<ul>
  <li>对 \(\delta \mathbf{v}_{j}\)</li>
</ul>

\[\frac{\partial{\mathbf{r}_{\triangle \mathbf{o}_{ij}}}}{\partial{\delta \mathbf{v}_{j}}} = 0\]

<ul>
  <li>对 \(\delta \mathbf{\phi}_{i}\)</li>
</ul>

\[\begin{align*}
\mathbf{r}_{\triangle \mathbf{o}_{ij}} \left( \mathrm{R}_{i} \mathbf{Exp} (\delta \phi_{i}) \right) &amp;= \left[ \mathrm{R}_{i} \mathbf{Exp} (\delta \phi_{i}) \right]^{T} \left( \mathbf{p}_{j} - \mathbf{p}_{i} \right) - \mathbf{t}_{O}^{B} + \left[ \mathrm{R}_{i} \mathbf{Exp} (\delta \phi_{i}) \right]^{T} \mathrm{R}_{j} \mathbf{t}_{O}^{B} + C \\[2mm]
&amp;= \left( \mathbf{I} - \delta \phi_{i}^{\wedge} \right) \mathrm{R}_{i}^{T} \left( \mathbf{p}_{j} - \mathbf{p}_{i} \right) - \mathbf{t}_{O}^{B} + \left( \mathbf{I} - \delta \phi_{i}^{\wedge} \right) \mathrm{R}_{i}^{T} \mathrm{R}_{j} \mathbf{t}_{O}^{B} + C \\[2mm]
&amp;= \mathrm{R}_{i}^{T} \left( \mathbf{p}_{j} - \mathbf{p}_{i} \right) - \mathbf{t}_{O}^{B} + \mathrm{R}_{i}^{T} \mathrm{R}_{j} \mathbf{t}_{O}^{B} + C \\
&amp;+ \left( -\delta \phi_{i}^{\wedge} \right) \mathrm{R}_{i}^{T} \left( 
   \mathbf{p}_{j} - \mathbf{p}_{i} + \mathrm{R}_{j} \mathbf{t}_{O}^{B}
 \right) \\[2mm]
&amp;= \mathbf{r}_{\triangle \mathbf{o}_{ij}} + \left[ \mathrm{R}_{i}^{T} \left( 
   \mathbf{p}_{j} - \mathbf{p}_{i} + \mathrm{R}_{j} \mathbf{t}_{O}^{B}
 \right) \right]^{\wedge} \delta \phi_{i}
\end{align*}\]

<p>注：</p>

\[\mathbf{Exp} (\phi)^{T} \simeq (\mathbf{I} + \phi^{\wedge})^{T} = \mathbf{I} + (\phi ^{\wedge})^{T} = \mathbf{I} - \phi^{\wedge}\]

<ul>
  <li>对 \(\delta \mathbf{\phi}_{j}\)</li>
</ul>

\[\begin{align*}
\mathbf{r}_{\triangle \mathbf{o}_{ij}} \left( \mathrm{R}_{j} \mathbf{Exp} (\delta \phi_{j}) \right)  &amp;= \mathrm{R}_{i}^{T} \left( \mathbf{p}_{j} - \mathbf{p}_{i} \right) - \mathbf{t}_{O}^{B} + \mathrm{R}_{i}^{T} \mathrm{R}_{j} \mathbf{Exp} (\delta \phi_{j}) \mathbf{t}_{O}^{B} + C \\[2mm]
&amp;= \mathrm{R}_{i}^{T} \left( \mathbf{p}_{j} - \mathbf{p}_{i} \right) - \mathbf{t}_{O}^{B} + \mathrm{R}_{i}^{T} \mathrm{R}_{j} (\mathbf{I} + \delta \phi_{j}^{\wedge}) \mathbf{t}_{O}^{B} + C \\[2mm]
&amp;=  \mathrm{R}_{i}^{T} \left( \mathbf{p}_{j} - \mathbf{p}_{i} \right) - \mathbf{t}_{O}^{B} + \mathrm{R}_{i}^{T} \mathrm{R}_{j} \mathbf{t}_{O}^{B} + C + \mathrm{R}_{i}^{T} \mathrm{R}_{j}\delta \phi_{j}^{\wedge} \mathbf{t}_{O}^{B} \\[2mm]
&amp;= \mathrm{R}_{i}^{T} \left( \mathbf{p}_{j} - \mathbf{p}_{i} \right) - \mathbf{t}_{O}^{B} + \mathrm{R}_{i}^{T} \mathrm{R}_{j} \mathbf{t}_{O}^{B} + C - \mathrm{R}_{i}^{T} \mathrm{R}_{j} (\mathbf{t}_{O}^{B})^{\wedge} \delta \phi_{j}
\end{align*}\]

<p>所以：</p>

\[\frac{\partial{\mathbf{r}_{\triangle \mathbf{o}_{ij}}}}{\partial{\delta \phi_{j}}} = - \mathrm{R}_{i}^{T} \mathrm{R}_{j} (\mathbf{t}_{O}^{B})^{\wedge}\]

<ul>
  <li>对 \(\tilde{\delta} \mathbf{b}_{i}^{g}\)</li>
</ul>

\[\frac{\partial{\mathbf{r}_{\triangle \mathbf{o}_{ij}}}}{\partial{\tilde{\delta} \mathbf{b}_{i}^{g}}} = -\frac{\partial{\bar{\mathbf{o}}_{ij}}}{\partial{\mathbf{b}_{i}^{g}}}\]

<ul>
  <li>对 \(\tilde{\delta} \mathbf{b}_{i}^{a}\)</li>
</ul>

\[\frac{\partial{\mathbf{r}_{\triangle \mathbf{o}_{ij}}}}{\partial{\tilde{\delta} \mathbf{b}_{i}^{a}}} = 0\]]]></content><author><name></name></author><category term="SLAM" /><category term="IMU," /><category term="Wheel," /><category term="Preintegration," /><category term="VINS" /><summary type="html"><![CDATA[轮速计噪声模型]]></summary></entry><entry><title type="html">VINS-Wheel</title><link href="https://renwuli.github.io/blog/2022/VINS-Wheel/" rel="alternate" type="text/html" title="VINS-Wheel" /><published>2022-10-10T12:00:00+00:00</published><updated>2022-10-10T12:00:00+00:00</updated><id>https://renwuli.github.io/blog/2022/VINS-Wheel</id><content type="html" xml:base="https://renwuli.github.io/blog/2022/VINS-Wheel/"><![CDATA[<p>Paper: Visual-Inertial Odometry Tightly Coupled with Wheel Encoder Adopting Robust Initialization and Online Extrinsic Calibration</p>

<p>PDF: <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8967607">https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8967607</a></p>

<h2 id="主要贡献">主要贡献：</h2>
<ul>
  <li>在预积分阶段融合IMU和轮速计，4-DoF非线性优化得到更加准确的尺度</li>
  <li>IMU-Camera-轮速计的联合初始化方法</li>
  <li>在线标定IMU-轮速计外参</li>
</ul>

<h2 id="硬件设置">硬件设置：</h2>
<p>后驱四轮车（当前面两个轮子旋转时，后面两个轮子的朝向不改变），轮速计安装在后左车轮。左后轮的速度方向始终朝向y轴。</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/vins-wheel/1-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/vins-wheel/1-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/vins-wheel/1-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/vins-wheel/1.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 1
</div>

<h2 id="流程">流程</h2>
<p>初始化 → 传感器坐标系与重力方向对齐，创建初始地图 → IMU、轮速计预积分，特征点提取与跟踪 → 滑动窗口非线性优化 → 当前帧的pvq计算得到</p>

<p>当初始化结束之后，外参便写死不再改变</p>

<h3 id="a-预积分">A. 预积分</h3>
<p>其实是VINS-MONO预积分公式的扩展（加入轮速计）</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/vins-wheel/2-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/vins-wheel/2-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/vins-wheel/2-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/vins-wheel/2.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 2
</div>

<p>在初始阶段，\(\hat{\alpha}_i^i, \hat{\beta}^i_i, \hat{\eta}^i_i\) 均为0，而 \(\hat{\gamma}^i_i\) 为单位四元数。</p>

<blockquote>
  <p>Joan Sola. Quaternion kinematics for the error-state kalman filter. arXiv preprint arXiv:1711.02508, 2017.</p>
</blockquote>

<p>参考上文，使用扰动方式计算出运动学公式，推导出协方差矩阵：</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/vins-wheel/3-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/vins-wheel/3-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/vins-wheel/3-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/vins-wheel/3.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 3
</div>

\[\delta z^i_{l+1} = B_{i,l}n＋A_{i,l}\delta z_{l}^i\]

\[\Sigma_{i, l+1} = B_{i,l}QB_{i,l}^T+A_{i,l}\Sigma_{i,l}A_{i,l}^T\]

<p>和VINS-MONO的对比下来看一下：</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/vins-wheel/4-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/vins-wheel/4-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/vins-wheel/4-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/vins-wheel/4.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 4
</div>

<p>这里面也讨论了一下VINS-MONO初始化的问题：</p>
<blockquote>
  <p>The initailization procedure of VINS is well-designed, but prone to error for a car with a monocular camera facing forward moving at approximately constant velocity.</p>
</blockquote>

<p>也就是说，如果车子以近似恒速的状态向前运动，VINS-MONO往往会出错。</p>

<h3 id="b-初始化">B. 初始化</h3>

<h4 id="陀螺仪bias">陀螺仪bias</h4>

<p>先像VINS-MONO一样做SFM，得到up-to-scale的视觉structure，然后与IMU进行手眼标定，通过旋转约束最小二乘计算得到陀螺仪的bias：</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/vins-wheel/5-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/vins-wheel/5-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/vins-wheel/5-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/vins-wheel/5.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 5
</div>

<p>得到新的陀螺仪bias \(\mathrm{b}_w\) 之后，重新预积分，以避免使用不精确的陀螺仪bias引入的累计误差。</p>

<h4 id="修正重力方向和初始化速度">修正重力方向和初始化速度</h4>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/vins-wheel/6-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/vins-wheel/6-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/vins-wheel/6-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/vins-wheel/6.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 6
</div>

<p>依然是和VINS-MONO类似的方程：</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/vins-wheel/7-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/vins-wheel/7-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/vins-wheel/7-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/vins-wheel/7.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 7
</div>

<p>因为轮速计的$XY$平面在定义时是和car的机壳水平的，所以可以近似地认为轮速计的 \(Z\) 方向是和重力方向一致的，将其转到body-imu坐标系下得到重力的初始值：</p>

\[g_0^{b0} = R_o^b[0 ~ 0 ~ g]^T\]

<p>之后进行重力方向的修正（重力的大小已知），和VINS-MONO类似，将重力方向在切平面处过参数化，引入两个新的切向量，进行优化：</p>

\[g^{b0} = g_0^{b0}+B\triangle g\]

<p>其中，$B$即为这两个切向量的基。</p>

<h3 id="c-非线性优化">C. 非线性优化</h3>
<p>cost function由三个部分组成：边缘化的term，重投影误差的term和IMU-轮速计的term。</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/vins-wheel/8-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/vins-wheel/8-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/vins-wheel/8-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/vins-wheel/8.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 8
</div>

<p>其中 \(e_s^k\) 是IMU-轮速计的residual，是我们重点关注的：</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/vins-wheel/9-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/vins-wheel/9-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/vins-wheel/9-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/vins-wheel/9.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 9
</div>

<p>上式对 \(b_{a_k}, b_{w_k}\) 和 \(R_o^b\) 求导，再求解到最优解。</p>

<h3 id="d-在线外参标定">D. 在线外参标定</h3>
<p>分为两个外参：camera-imu外参和imu-odemetry外参。但是作者也说了，当整个系统没有良好的约束时（比如缺乏旋转、IMU没有良好的激励），动态地调整外参可能会导致系统运行失败。</p>

<blockquote>
  <p>Consider that one cannot distinguish the direction of local gravity from that of the accelerometer bias when there is no rotational motion, which is pointed out in [6]. That is to say, the lack of constraints will result in the unstable estimation of accelerometer bias. Conversely, the convergence of accelerometer bias indicates that the system has become well-constrained.</p>
</blockquote>

<p><strong>当加速度计的bias很好地收敛，那就意味着整个系统有良好的约束。</strong></p>

<h2 id="参考文献">参考文献</h2>
<p>[1] Tong Qin, Peiliang Li, and Shaojie Shen. Vins-mono: A robust and versatile monocular visual-inertial state estimator. IEEE Transactions on Robotics, 34(4):1004–1020, 2018.</p>

<p>[2] Meixiang Quan, Songhao Piao, Minglang Tan, and Shi-Sheng Huang. Tightly-coupled monocular visual-odometric slam using wheels and a mems gyroscope. arXiv preprint arXiv:1804.04854, 2018.</p>

<p>[3] Shaojie Shen, Nathan Michael, and Vijay Kumar. Tightly-coupled monocular visual-inertial fusion for autonomous flight of rotorcraft mavs. In Robotics and Automation (ICRA), 2015 IEEE International Conference on, pages 5303–5310. IEEE, 2015.</p>

<p>[4] 轮式编码器与VIO的融合（一）. https://zhuanlan.zhihu.com/p/149484507</p>

<p>[5] 胡占义-中国科学院大学-UCAS. https://people.ucas.ac.cn/~huzhanyi</p>]]></content><author><name></name></author><category term="SLAM" /><category term="IMU," /><category term="Wheel," /><category term="Preintegration," /><category term="VINS" /><summary type="html"><![CDATA[Paper: Visual-Inertial Odometry Tightly Coupled with Wheel Encoder Adopting Robust Initialization and Online Extrinsic Calibration]]></summary></entry><entry><title type="html">IMU Preintegration</title><link href="https://renwuli.github.io/blog/2022/IMU-Preintegration/" rel="alternate" type="text/html" title="IMU Preintegration" /><published>2022-10-01T10:00:00+00:00</published><updated>2022-10-01T10:00:00+00:00</updated><id>https://renwuli.github.io/blog/2022/IMU-Preintegration</id><content type="html" xml:base="https://renwuli.github.io/blog/2022/IMU-Preintegration/"><![CDATA[<p>本文基于Foster2016年发表在 <em>IEEE Transactions on Robotics</em> 上的一篇文章：<em>On-Manifold Preintegration for Real-Time Visual-Inertial Odometry</em>。</p>

<h2 id="imu噪声模型">IMU噪声模型</h2>
<p>6自由度的IMU有三轴加速度和三轴角速度。</p>

\[_{B}\widetilde{\omega}_{WB}(t) = _{B}\omega_{WB}(t) + \mathrm{b}^{g}(t) + \mathrm{\eta}^{g}(t)\]

\[_{B}\widetilde{a}(t) = \mathrm{R}_{WB}^{T}(t)(_{W}\mathrm{a}(t) - _{W}\mathrm{g}) + \mathrm{b}^{a}(t) + \mathrm{\eta}^{a}(t)\]

<p>以上分别为IMU坐标系下的角速度和加速度，IMU系的加速度为世界坐标系下的加速度去除重力加速的影响再转到IMU坐标系，上面的表达都忽略了地球的自转。加速度和角速度都各自受其偏置和随机游走噪声影响，这里认为偏置和随机游走噪声都是关于时间的函数，也就是说偏置和噪声不是一成不变的。</p>

<h2 id="imu运动模型">IMU运动模型</h2>

\[\dot{\mathrm{R}}_{WB} = \mathrm{R}_{WB} ~ _{B} \omega_{WB}^{\wedge}\]

\[_{W} \dot{\mathrm{v}} = _{W}\mathrm{a}\]

\[_{W} \dot{\mathrm{p}} = _{W}\mathrm{v}\]

<h2 id="相邻时刻的rvp递推">相邻时刻的RVP递推</h2>
<p>IMU自身坐标系到世界坐标系的旋转：</p>

\[\mathrm{R}_{WB}(t + \triangle t) = \mathrm{R}_{WB} \mathrm{Exp}\left( \int_{t}^{t + \triangle t} { _{B}\omega_{WB}(\tau) d\tau} \right)\]

<p>世界坐标系下的速度：</p>

\[_{W} \mathrm{v}(t + \triangle t) = _{W} \mathrm{v}(t) + \int_{t}^{t + \triangle t} {_{W} \mathrm{a} (\tau) d\tau}\]

<p>世界坐标系下的位移：</p>

\[_{W} \mathrm{p}(t + \triangle t) = _{W} \mathrm{p}(t) + \int_{t}^{t + \triangle t} {_{W} \mathrm{v} (\tau) d\tau} + \iint_{t}^{t + \triangle t} {_{W} \mathrm{a}(\tau) d\tau^{2}}\]

<p>以上是相邻时刻IMU的三个状态的递推，如果我们假设在\([t, t + \triangle t]\)内，世界坐标系下的加速度 \(_{W}\mathrm{a}\) 和IMU坐标系下的角速度 \(_{B}\omega _{WB}\) 保持恒定，那么可以将上述连续形式下的递推改写为如下离散形式：</p>

\[\mathrm{R}_{WB} (t + \triangle t) = \mathrm{R}_{WB} (t) \mathrm{Exp} \left( _{B}\omega _{WB}(t) \triangle t \right)\]

\[_{W}\mathrm{v}(t + \triangle t) = _{W}\mathrm{v}(t) + _{W}\mathrm{a}(t) \triangle t\]

\[_{W}\mathrm{p}(t + \triangle t) = _{W}\mathrm{p}(t) + _{W}\mathrm{v}(t) \triangle t + \frac{1}{2} _{W}\mathrm{a}(t) \triangle t^{2}\]

<p>将\(\mathrm{R}_{WB}\) 记作\(\mathrm{R}\)，默认速度 \(\mathrm{v}\)、位移 \(\mathrm{p}\)、重力加速度 \(\mathrm{g}\) 和加速度 \(\mathrm{a}\) 为世界坐标系下的量，而角速度 \(\omega\) 为IMU坐标系下的量，则：</p>

\[\mathrm{R} (t + \triangle t) = \mathrm{R} (t) \mathrm{Exp} \left( \omega (t) \triangle t \right)\]

\[\mathrm{v}(t + \triangle t) = \mathrm{v}(t) + \mathrm{a}(t) \triangle t\]

\[\mathrm{p}(t + \triangle t) = \mathrm{p}(t) + \mathrm{v}(t) \triangle t + \frac{1}{2} \mathrm{a}(t) \triangle t^{2}\]

<p>考虑噪声模型，有：
\(\mathrm{R} (t + \triangle t) = \mathrm{R} (t) \mathrm{Exp} \left( \left( \tilde{\omega} - \mathrm{b}^{g}(t) - \mathrm{\eta}^{gd}(t) \right)  (t) \triangle t \right)\)</p>

\[\mathrm{v}(t + \triangle t) = \mathrm{v}(t) + \mathrm{g}\triangle t + \left( \tilde{\mathrm{a}}(t) - \mathrm{b}^{a}(t) - \mathrm{\eta}^{ad}(t) \right)  \triangle t\]

\[\mathrm{p}(t + \triangle t) = \mathrm{p}(t) + \mathrm{v}(t) \triangle t + \frac{1}{2}  \mathrm{g}\triangle t^{2} + \frac{1}{2} \mathrm{R}(t) \left( \tilde{\mathrm{a}}(t) - \mathrm{b}^{a}(t) - \mathrm{\eta}^{ad}(t) \right) \triangle t^{2}\]

<h2 id="关键帧之间的rvp递推">关键帧之间的RVP递推</h2>

\[\mathrm{R}_{j} = \mathrm{R}_{i} \prod_{k=i}^{j-1} \mathrm{Exp} \left( \left( \tilde{\omega}_{k} - \mathrm{b}_{k}^{g} - \mathrm{\eta}_{k}^{gd} \right) \triangle t \right)\]

\[\mathrm{v}_{j} = \mathrm{v}_{i} + \mathrm{g} \triangle t_{ij} + \sum_{k=i}^{j-1} \mathrm{R}_{k} \left( \tilde{\mathrm{a}}_k - \mathrm{b}_k^{a} - \mathrm{\eta}_k^{ad} \right) \triangle t\]

\[\mathrm{p}_{j} = \mathrm{p}_{i} + \sum_{k=i}^{j-1} \left[ \mathrm{v}_{k} \triangle t + \frac{1}{2} \mathrm{g} \triangle t^{2} + \frac{1}{2} \mathrm{R}_{k} \left( \tilde{\mathrm{a}}_{k} - \mathrm{b}_{k}^{a} - \mathrm{\eta}_{k}^{ad} \right) \triangle t^{2}  \right]\]

<p>借助上面三个公式，假如已知 \(i\) 时刻的RVP状态，就可以推得 \(j\) 时刻的RVP状态，但是在优化过程中，一旦 \(\mathrm{R}_{i}\) 发生变化，要求得 \(j\) 时刻的RVP状态，需要重新进行高计算量的积分，因此引入预积分，只需要将 \(\triangle  \mathrm{R}_{ij}\) 这个中间增量求出来即可。</p>

<h2 id="预积分">预积分</h2>

<p>将第 \(i\) 时刻的状态和重力加速度分离出来</p>

\[\triangle  \mathrm{R}_{ij} = \mathrm{R}_{i}^{T} \mathrm{R}_{j} = \prod_{k=i}^{j-1} \mathrm{Exp} \left( \left( \tilde{\omega}_{k} - \mathrm{b}_{k}^{g} - \mathrm{\eta}_{k}^{gd} \right) \triangle t \right)\]

\[\mathrm{v}_{j} - \mathrm{v}_{i} - \mathrm{g} \triangle t_{ij} = \sum_{k=i}^{j-1} \mathrm{R}_{k} \left( \tilde{\mathrm{a}}_k - \mathrm{b}_k^{a} - \mathrm{\eta}_k^{ad} \right) \triangle t\]

<p>转换到第 \(i\) 时刻的IMU坐标系，得：</p>

\[\begin{align*}
\triangle \mathrm{v}_{ij} &amp;= \mathrm{R}_{i}^{T} \left( \mathrm{v}_{j} - \mathrm{v}_{i} - \mathrm{g} \triangle t_{ij} \right) \\
&amp;= \sum_{k=i}^{j-1} \mathrm{R}_{ik} \left( \tilde{\mathrm{a}}_k - \mathrm{b}_k^{a} - \mathrm{\eta}_k^{ad} \right) \triangle t 
\end{align*}\]

<p>同理：</p>

\[\begin{align*}
\triangle \mathrm{p}_{ij} &amp;= \mathrm{R}_{i}^{T} \left( \mathrm{p}_{j} - \mathrm{p}_{i} - \mathrm{v}_{i} \triangle t_{ij} - \frac{1}{2} \mathrm{g} \triangle t_{ij}^{2}  \right) \\
&amp;= \sum_{k=i}^{j-1} \left[ \mathrm{v}_{ik} \triangle t + \frac{1}{2} \triangle \mathrm{R}_{ik} \left( \tilde{\mathrm{a}}_{k} - \mathrm{b}_{k}^{a} - \mathrm{\eta}_{k}^{ad} \right) \triangle t^{2} \right]
\end{align*}\]

<p>由此，上面三个式子的 rhs 便与第 \(i\) 时刻和重力加速度无关，并且可以直接用第 \(i\) 关键帧和第 \(j\) 关键帧之间的IMU数据积分而来。</p>

<h3 id="分离噪声">分离噪声</h3>

<p>将上述预积分公式中的噪声分离出来，我们得到一个 <strong>与噪声无关的项 + 噪声</strong>的形式：</p>

\[\begin{align*}
  \triangle \mathrm{R}_{ij} &amp;= \prod_{k=i}^{j-1} \left[ 
  \mathrm{Exp} \left( 
    \left( 
      \tilde{\omega}_{k} - \mathrm{b}_{i}^{g} \triangle t
     \right)
   \right)
  \mathrm{Exp} \left( 
    -\mathrm{J}_{r}^{k} \mathrm{\eta}_{k}^{gd} \triangle t
   \right)
 \right] \\
 &amp;= \triangle \tilde{\mathrm{R}}_{ij} \prod_{k=i}^{j-1} \mathrm{Exp} \left( 
  - \triangle \tilde{\mathrm{R}}_{k+1 j}^{T} \mathrm{J}_{r}^{k}\mathrm{\eta}_{k}^{gd} \triangle t
  \right) \\
 &amp;= \triangle \tilde{\mathrm{R}}_{ij} \mathrm{Exp} \left( -\delta \phi_{ij} \right)
\end{align*}\]

<p>其中，\(\triangle \tilde{\mathrm{R}}_{ij} = \prod_{k=i}^{j-1} \mathrm{Exp} \left(\left(\tilde{\omega}_{k} - \mathrm{b}_{i}^{g}\right) \triangle t \right)\)。</p>

<p>将分离噪声之后的 \(\triangle \tilde{\mathrm{R}}_{ij}\) 带入到本节开头的预积分公式中去，可以得到速度和加速度预积分的第二个形式：</p>

\[\triangle \mathrm{v}_{ij} = \triangle \tilde{\mathrm{v}}_{ij} - \delta \mathrm{v}_{ij}\]

<p>其中：</p>

\[\triangle \tilde{\mathrm{v}_{ij}} = \sum_{k=i}^{j-1} \left[ 
  \triangle \tilde{\mathrm{R}}_{ij} \left( 
    \tilde{\mathrm{a}}_{k} - \mathrm{b}_{i}^{a}
   \right) \triangle t
 \right]\]

<p>对于位移，同样有：</p>

\[\triangle \mathrm{p}_{ij} = \triangle \tilde{\mathrm{p}}_{ij} - \delta \mathrm{p}_{ij}\]

<p>将上述三式带入到本节开头的预积分公式中，也就是：</p>

\[\triangle \mathrm{R}_{ij} = \mathrm{R}_{i}^{T} \mathrm{R}_{j}\]

\[\triangle \mathrm{v}_{ij} = \mathrm{R}_{i}^{T} \left( \mathrm{v}_{j} - \mathrm{v}_{i} - \mathrm{g} \triangle t_{ij} \right)\]

<p>\(\triangle \mathrm{p}_{ij} = \mathrm{R}_{i}^{T} \left( \mathrm{p}_{j} - \mathrm{p}_{i} - \mathrm{v}_{i} \triangle t_{ij} - \frac{1}{2} \mathrm{g} \triangle t_{ij}^{2}  \right)\)
得：
\(\triangle \tilde{\mathrm{R}}_{ij} = \mathrm{R}_{i}^{T} \mathrm{R}_{j} \mathrm{Exp} \left( \delta \phi_{ij} \right)\)</p>

\[\triangle \tilde{\mathrm{v}}_{ij} = \mathrm{R}_{i}^{T} \left( \mathrm{v}_{j} - \mathrm{v}_{i} - \mathrm{g} \triangle t_{ij} \right) + \delta \mathrm{v}_{ij}\]

\[\triangle \tilde{\mathrm{p}}_{ij} = \mathrm{R}_{i}^{T} \left( \mathrm{p}_{j} - \mathrm{p}_{i} - \mathrm{v}_{i} \triangle t_{ij} - \frac{1}{2} \mathrm{g} \triangle t_{ij}^{2}  \right) + \delta \mathrm{p}_{ij}\]

<p>那么预积分噪声向量便可定义为：</p>

\[\mathrm{\eta}_{ij}^{\triangle} =
\begin{bmatrix}
  \delta \phi_{ij}, \delta \mathrm{v}_{ij}, \delta \mathrm{p}_{ij}
\end{bmatrix}^{T}\]

<h3 id="噪声传播">噪声传播</h3>
<p>对预积分噪声 \(\mathrm{\eta}_{ij}^{\triangle}\) 做一阶近似，得:</p>

\[\delta \phi_{ij} \simeq \sum_{k=i}^{j-1} \triangle \tilde{\mathrm{R}}_{k+1 j}^{T} \mathrm{J}_{r}^{k} \eta_{k}^{gd} \triangle t\]

\[\delta \mathrm{v}_{ij} \simeq \sum_{k=i}^{j-1} \left[ 
  - \triangle \tilde{\mathrm{R}}_{ik} \left( 
    \tilde{\mathrm{a}}_{k} - \mathrm{b}_{i}^{a}
   \right)^{\wedge} \delta \phi_{ik} \triangle t + 
   \triangle \tilde{\mathrm{R}}_{ik} \eta_{k}^{ad} \triangle t
 \right]\]

\[\delta \mathrm{p}_{ij} \simeq \sum_{k=i}^{j-1} \left[ 
  \delta \mathrm{v}_{ik} \triangle t - \frac{1}{2} \triangle \tilde{\mathrm{R}}_{ik} \left( 
    \tilde{\mathrm{a}}_{k} - \mathrm{b}_{i}^{a}
   \right)^{\wedge}  \delta \phi_{ik} \triangle t^{2} + \frac{1}{2} \triangle \tilde{\mathrm{R}}_{ik} \eta_{k}^{ad} \triangle t^{2}
 \right]\]

<p>上式说明预积分噪声 \(\mathrm{\eta}_{ij}^{\triangle}\) 是关于IMU测量模型 \(\mathrm{\eta}_{k}^{d} = \left[ \mathrm{\eta}_{k}^{gd}, \mathrm{\eta}_{k}^{ad} \right]\) 的线性函数，因此，若已知IMU噪声 \(\mathrm{\eta}_{k}^{d}\) 的协方差矩阵，那么预积分噪声的协方差矩阵可以自然而然推出来。</p>

<h3 id="偏置更新">偏置更新</h3>

<p>在之前的内容中都假设偏置在关键帧 \(i\) 和关键帧  \(j\) 内是一成不变的，但实际上这是不可能滴。如果在偏置每次改变的时候都重新计算一下IMU观测和预积分，那是大大得耗费资源，是不可取滴。所以这里也把预积分项改写为关于偏置的一阶线性近似函数：</p>

\[\begin{align*}
\triangle \tilde{\mathrm{R}}_{ij}(\mathrm{b}_{i}^{g}) \simeq \triangle \tilde{\mathrm{R}}_{ij} (\bar{\mathrm{b}}_{i}^{g}) \mathrm{Exp} \left( 
  \frac{\partial{\triangle \tilde{\mathrm{R}}_{ij}}}{\partial{\mathrm{b}^{g}}} \delta \mathrm{b}^{g}
 \right) \\
\triangle \tilde{\mathrm{v}}_{ij}(\mathrm{b}_{i}^{g}, \mathrm{b}_{i}^{a}) \simeq \triangle \tilde{\mathrm{v}}_{ij} (\bar{\mathrm{b}}_{i}^{g}, \bar{\mathrm{b}}_{i}^{a}) + \frac{\partial{\tilde{\mathrm{v}}_{ij}}}{\partial{\mathrm{b}^{g}}} \delta \mathrm{b}^{g} + \frac{\partial{\tilde{\mathrm{v}}_{ij}}}{\partial{\mathrm{b}^{a}} } \delta \mathrm{b}^{a} \\
\triangle \tilde{\mathrm{p}}_{ij}(\mathrm{b}_{i}^{g}, \bar{\mathrm{b}}_{i}^{a}) \simeq \triangle \tilde{\mathrm{p}}_{ij} (\bar{\mathrm{b}}_{i}^{g}, \bar{\mathrm{b}}_{i}^{a}) + \frac{\partial{\tilde{\mathrm{p}}_{ij}}}{\partial{\mathrm{b}^{g}}} \delta \mathrm{b}^{g} + \frac{\partial{\tilde{\mathrm{p}}_{ij}}}{\partial{\mathrm{b}^{a}} } \delta \mathrm{b}^{a}
\end{align*}\]

<h3 id="预积分因子">预积分因子</h3>

\[\mathrm{r}_{\triangle \mathrm{R}_{ij}} = \mathrm{Log} \left( 
  \left( 
    \triangle \tilde{\mathrm{R}}_{ij} (\bar{\mathrm{b}}_{i}^{g}) \mathrm{Exp} \left( 
  \frac{\partial{\triangle \tilde{\mathrm{R}}_{ij}}}{\partial{\mathrm{b}^{g}}} \delta \mathrm{b}^{g}
 \right)
   \right)^{T}
  \mathrm{R}_{i}^{T} \mathrm{R}_{j}
 \right)\]

\[\mathrm{r}_{\triangle \mathrm{v}_{ij}} = \mathrm{R}_{i}^{T} \left( \mathrm{v}_{j} - \mathrm{v}_{i} - \mathrm{g} \triangle t_{ij} \right) - \left[ 
  \triangle \tilde{\mathrm{v}}_{ij} (\bar{\mathrm{b}}_{i}^{g}, \bar{\mathrm{b}}_{i}^{a}) + \frac{\partial{\tilde{\mathrm{v}}_{ij}}}{\partial{\mathrm{b}^{g}}} \delta \mathrm{b}^{g} + \frac{\partial{\tilde{\mathrm{v}}_{ij}}}{\partial{\mathrm{b}^{a}} } \delta \mathrm{b}^{a}
 \right]\]

\[\mathrm{r}_{\triangle \mathrm{p}_{ij}} = \mathrm{R}_{i}^{T} \left( \mathrm{p}_{j} - \mathrm{p}_{i} - \mathrm{v}_{i} \triangle t_{ij} - \frac{1}{2} \mathrm{g} \triangle t_{ij}^{2}  \right) - \left[ 
  \triangle \tilde{\mathrm{p}}_{ij} (\bar{\mathrm{b}}_{i}^{g}, \bar{\mathrm{b}}_{i}^{a}) + \frac{\partial{\tilde{\mathrm{p}}_{ij}}}{\partial{\mathrm{b}^{g}}} \delta \mathrm{b}^{g} + \frac{\partial{\tilde{\mathrm{p}}_{ij}}}{\partial{\mathrm{b}^{a}} } \delta \mathrm{b}^{a}
 \right]\]

<h2 id="坐标系">坐标系</h2>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/imu-preintegrated/frames-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/imu-preintegrated/frames-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/imu-preintegrated/frames-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/imu-preintegrated/frames.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Coordinate systems
</div>]]></content><author><name></name></author><category term="SLAM" /><category term="IMU," /><category term="Preintegration," /><category term="ORBSLAM3" /><summary type="html"><![CDATA[Dive into IMU preintegration]]></summary></entry><entry><title type="html">NeRD</title><link href="https://renwuli.github.io/blog/2022/NeRD/" rel="alternate" type="text/html" title="NeRD" /><published>2022-04-01T15:00:00+00:00</published><updated>2022-04-01T15:00:00+00:00</updated><id>https://renwuli.github.io/blog/2022/NeRD</id><content type="html" xml:base="https://renwuli.github.io/blog/2022/NeRD/"><![CDATA[<p>Paper: NeRD: Neural 3D Reflection Symmetry Detector</p>

<p>Author: Yichao Zhou, Shichen Liu, Yi Ma</p>

<p>PDF: <a href="https://arxiv.org/pdf/2105.03211.pdf">https://arxiv.org/pdf/2105.03211.pdf</a></p>

<p>Code: <a href="https://github.com/zhou13/nerd">https://github.com/zhou13/nerd</a></p>

<h2 id="overview">Overview</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: left">输入</th>
      <th style="text-align: left">输出</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">单视角图片</td>
      <td style="text-align: left">一个主导的镜面对称</td>
    </tr>
  </tbody>
</table>

<p>总体方法：</p>
<ol>
  <li>使用coarse-to-fine的策略对symmetry进行遍历</li>
  <li>通过构造3D的代价体来找到最好的symmetry</li>
</ol>

<h2 id="introduction">Introduction</h2>

<p>使用监督学习从单张RGB图片中获取信息很容易 \(\rightarrow\) 假设CAD模型已知，一些工作聚焦在instance-level 3D pose estimation \(\rightarrow\) 现实世界中这个假设很难成立（一个物体的CAD模型很难获取）\(\rightarrow\) 之前的一些single-view category-level 3D pose estimation的工作通过在训练数据中进行插值来构建图像和3D模型之间的集合约束进而预测姿态 \(\rightarrow\) 但是这种formulation是ill-posed  \(\rightarrow\) 引入镜面对称（reflection symmetry）作为图片和3D模型的位姿之间的桥梁。</p>

<p>观察：大部分物体的canonical space是将其对称平面与Y-Z平面进行对齐。</p>

<p>Contributiion:</p>

<ul>
  <li>图像内的像素对应可以用来得到准确的对称平面法向估计</li>
  <li>使用single-view dense feature matching来预测对称平面，性能超越之前的工作</li>
  <li>对称性对很多下游任务都有助益，比如single-view姿态估计和深度估计</li>
</ul>

<h2 id="methods">Methods</h2>

<h3 id="检验对称性">检验对称性</h3>

<p>对于三维空间中的两个对称点 \(\mathrm{X}\) 和 \(\mathrm{X}^{'}\) 来说，其在成像平面上的投影为 \(\mathrm{x}\) 和 \(\mathrm{x}^{'}\)，则：</p>

\[\mathrm{x}^{'} \propto \mathrm{KR_t M R_t^{-1}K^{-1}x = Cx}\]

<p>其中 \(\mathrm{C = KR_t M R_t^{-1}K^{-1}}\)。</p>

<p>将镜面对称参数化为 \(\mathrm{w} \in \mathbb{R}^3\)（代表对称平面的法向），那么：</p>

\[\mathrm{
    C(w) = K(I - \frac{2}{\Vert w \Vert_2^2}
    \begin{bmatrix}
    \mathrm{w} \\ 0
    \end{bmatrix}
    \begin{bmatrix}
    \mathrm{w}^T &amp; 1
    \end{bmatrix}
    )K^{-1}
}\]

<p>也就是说 \(\mathrm{C}\) 是 \(\mathrm{w}\) 的函数，并且相应地给出一种检验其是否合法的方法。</p>

<h3 id="预测">预测</h3>
<p>使用神经网络去遍历所有可能的对称平面法向，然后检验是否是合法的对称性。</p>

<h3 id="pipeline">Pipeline</h3>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/nerd/1-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/nerd/1-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/nerd/1-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/nerd/1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 1
</div>

<p>对于输入的图片，首先计算2D特征图，然后生成一堆候选的对称平面法向，对于每个候选的法向 \(\mathrm{w}\)，把2D特征图warp过去，构建一个3D的代价体进行photo-consistency的匹配，最后，cost volume网络将代价体转换为置信值，将具有最大置信度的 \(\mathrm{w}\) 作为最终的预测对称平面。</p>

<p>那么，如何去生成候选的对称平面法向呢？因为 \(\mathrm{w}\) 的定义域 \(\mathbb{R}^3\) 是连续的，如果使用暴力采样，将会使得复杂度极高。所以该文采用了coarse-to-fine的策略，先均匀采样，然后校验得到置信度最大的 \(\mathrm{w}^\star\)，之后将采样范围缩小到 \(\mathrm{w}^\star\) 附近，再次迭代，直到能够达到<strong>the desired accuracy</strong>。</p>

<p>特征提取器选择ResNet的变种，对于采样得到的 \(\mathrm{w}_i\) 来说，得到其transformation矩阵 \(\mathrm{C}(\mathrm{w}_i)\)。对于图像中的每一个像素点 \((x, y)\) 通过对称得到其对称点 \((x^{'}, y^{'})\)，将这两个像素点的特征concat在一起作为feature warping，得到代价体，之后代价体送入cost volume network（也就是一系列的3D convolution + max-pool + sigmoid）得到 \(\mathrm{w}_i\) 对应的置信度 \(\hat{l}_i\)。</p>

<h3 id="训练">训练</h3>
<p>在coarse-to-fine的每一level而言，分别在ground truth: \(\mathrm{w}\) 周边进行采样，对采样得到的 \(\hat{\mathrm{w}}\)，其标签为：</p>

\[l_i = 1[\mathrm{arccos}(\vert &lt;\mathrm{w}, \hat{\mathrm{w}}&gt; \vert) \lt \triangle_i]\]

<p>损失函数为：</p>

\[L_{\mathrm{cls}} = \sum_i \mathrm{BCE}(\hat{l_i}, l_i)\]

<h2 id="applications">Applications</h2>

<h3 id="pose-recovery">Pose Recovery</h3>

<p>不太明白这里的2 DoFs</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/nerd/2-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/nerd/2-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/nerd/2-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/nerd/2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 2
</div>

<h3 id="depth-estimation">Depth Estimation</h3>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/nerd/3-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/nerd/3-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/nerd/3-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/nerd/3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 3
</div>]]></content><author><name></name></author><category term="Geometry," /><category term="NN" /><category term="Symmetry" /><summary type="html"><![CDATA[Paper: NeRD: Neural 3D Reflection Symmetry Detector]]></summary></entry><entry><title type="html">SymmetryNet</title><link href="https://renwuli.github.io/blog/2022/SymmetryNet/" rel="alternate" type="text/html" title="SymmetryNet" /><published>2022-04-01T15:00:00+00:00</published><updated>2022-04-01T15:00:00+00:00</updated><id>https://renwuli.github.io/blog/2022/SymmetryNet</id><content type="html" xml:base="https://renwuli.github.io/blog/2022/SymmetryNet/"><![CDATA[<p>Paper: SymmetryNet: Learning to Predict Reflectional and Rotational
Symmetries of 3D Shapes from Single-View RGB-D Images</p>

<p>Author: YIFEI SHI, JUNWEN HUANG, HONGJIA ZHANG, XIN XU, SZYMON RUSINKIEWICZ, KAI XU</p>

<p>PDF: <a href="https://arxiv.org/pdf/2008.00485.pdf">https://arxiv.org/pdf/2008.00485.pdf</a></p>

<p>Code: <a href="https://github.com/GodZarathustra/SymmetryNet">https://github.com/GodZarathustra/SymmetryNet</a></p>

<h2 id="overview">Overview</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: left">输入</th>
      <th style="text-align: right">输出</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">RGB-D</td>
      <td style="text-align: right">\(M^{\text{ref}}\) 个镜面对称和 \(M^{\text{rot}}\) 个旋转对称</td>
    </tr>
  </tbody>
</table>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/symmetrynet/1-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/symmetrynet/1-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/symmetrynet/1-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/symmetrynet/1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 1
</div>

<p>总体方法：</p>
<ol>
  <li>特征提取：RGB图像输入CNN网络中提取逐像素特征，Depth深度图转成点云输入PointNet提取逐点特征，之后将图像特征和点云特征进行Fusion。</li>
  <li>以每个点的特征作为输入，逐点进行对称性预测。</li>
  <li>最后通过aggregation和可视性验证对逐点对称性进行过滤和集成，得到最终的对称性预测结果。</li>
</ol>

<h2 id="introduction">Introduction</h2>

<p>对称性检测可以通过纯几何信息进行求解，比如先建立点到点之间的对应关系，得到大量的点对之间的对称性变换，然后通过霍夫投票得到全局的对称性 \(\rightarrow\) 但是这种方法在single-view（几何信息不足，partial observation and object occlusion）的情况下面临挑战，有可能找不到局部的对称点对来支撑全局的对称性 \(\rightarrow\) 所以当前的对称性检测不仅仅需要依赖几何信息，也需要来自于统计分析（也就是从大量数据中去学习patten）。</p>

<h2 id="methods">Methods</h2>

<p>该文claim一旦3D模型的几何已知，那么得到它的对称性是分分钟的事情（真的这么简单吗？我看未必）。传统的对称性检测方法通常先建立点或者组件之间的correspondence，然后再aggragate得到对称性。但是single-view的表征通常是不完整和视角受限的。在不完整几何上做对称性检测是病态的。通常我们去识别一个不完整物体对称性的时候，会去靠先验来判别这个对称性是不是歧义的。但是对于一个我们不认识的物体或者说辨别不出来是什么种类的物体，我们没有先验，那么只能通过建立对称的correspondence来推测出对称性。这篇文章主要聚焦的问题就是：<strong>对于认识或者不认识的物体，通过将对称性预测和对称映射耦合起来，构造一个统一的single-view的对称性检测方案</strong>。</p>

<h3 id="逐点的对称性预测">逐点的对称性预测</h3>

<p>因为对称性是non-local的，所以需要共同使用全局特征和局部特征来进行逐点对称性的预测。因为avg-pooling对于对称性预测是冗余的，max-pooling可能会丢失太多信息，该文采用weighted pooling，也就是对每个点的特征赋予一个权重，然后进行加权求和得到全局特征，该权重也是通过一个小网络学出来的，叫做spatially weighted pooling layer。</p>

<p>为了提高精度和泛化性，采用multi-task策略进行训练，也就是：</p>
<ol>
  <li>分类，判别对称性种类：no symmetry / reflective symmetry / rotational symmetry</li>
  <li>回归对称性的参数</li>
  <li>回归该点的对称点位置</li>
  <li>分类，判别该点是不是某个点的对称点</li>
</ol>

<p>为了让网络更加好训，所有预测的3D坐标均是相对于当前点的局部坐标，对于以上4部分，分别设计loss如下：</p>
<ol>
  <li>cross-entropy</li>
  <li>当前点 \(P_i\) 投影到到预测的对称平面（对称轴）的点与真实的投影点之间的2范数</li>
  <li>2范数</li>
  <li>cross-entropy</li>
</ol>

<p>对于旋转对称来说，我们去做上面3的loss不太容易，因为一个点的旋转对称点有可能有多个（旋转对称的阶数有穷）或无穷多个（连续的旋转对称），所以该文选择不直接对3做L2的loss，而是去预测某点在不在该点对应的旋转对称轨道上的概率。并且通过将预测旋转对称的阶数转换成一个分类的问题，也就是0-R类，0代表连续旋转对称，R代表所能预测的最大旋转对称阶数，该文将R取作10，也就是说该文能预测的最大的旋转对称的阶数为10。</p>

<h3 id="处理任意数目的对称性">处理任意数目的对称性</h3>
<p>如果要处理任意数目的对称性预测，要不设计一个循环神经网络（显然是不现实的，因为我要知道到底循环多少次？），要么是引出M个分支来预测M个对称性（其中M是设定的最大对称性的数目）。但是采用后者的策略需要将M个分支各自区分开来（也就是定义顺序），该文采用基于optimal assignment的方法来训练网络。也就是将M个输出与GT对应起来。</p>

<p>对于那些已经被判断对称性种类的分类器验证（输出不为0）的对称性预测值，找到它所对应的GT对称性，然后求loss。</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/symmetrynet/2-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/symmetrynet/2-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/symmetrynet/2-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/symmetrynet/2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 2
</div>

<p>虽然这里是说处理任意数目的对称性，但是显然，依然受上一节中 R=10 的限制。</p>

<h3 id="对称性推理">对称性推理</h3>

<p>在推理阶段，首先编码得到RGB-D的特征，然后对每个点进行对称性预测，然后使用聚类的方式得到最终的全局对称性预测结果。因为每个点预测对称性的准确性有差异，这里通过对symmetry type classifier的最后一层接一个概率层，得到每个点预测结果的权重，之后将这个概率作为DBSCAN中的密度权重，通过聚类得到最终的预测结果。</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/symmetrynet/3-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/symmetrynet/3-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/symmetrynet/3-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/symmetrynet/3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 3
</div>

<p>得到预测的对称性结果之后，还需要做的是对称性的检验，通过检验的对称性留下，没有通过检验的去除。将深度图转换为提速表示，将空间划分为三部分：可视部分，空气部分和未知部分，然后得到可视部分的对称部分，将对称部分与空气部分求交，便得到了mismatch的部分（很容易理解，如果对称部分是合理的，那么我摄像头应该本来就能看到，按理来说应该是可视部分，但是现在却为空气部分，说明不合理）。如果mismatch的部分太大，就说明该对称性预测的不对。这个策略作者也在训练阶段作为一项额外的约束进行了尝试，但是发现收敛太慢，所以就只在推理完之后作为一个验证手段。</p>

<h2 id="评价标准">评价标准</h2>

<p>该文使用precision-recall指标来评价对称性预测的好与坏，其中precision代表我预测的对称性中有多大比例是正确的，而recall代表GT中的对称性我有多大的比例正确预测出来了。</p>

<p>关于如何衡量预测的对称性是正确还是错误，作者给出了一个简单的评估指标：将模型按照预测的对称性对称过去，然后求原模型和对称模型的距离，该距离与GT对称性求得的距离做损失来打分。</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/symmetrynet/4-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/symmetrynet/4-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/symmetrynet/4-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/symmetrynet/4.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Figure 4
</div>

<h2 id="implementation">Implementation</h2>

<p>读完paper有一个问题，如果每个模型都预测$M$个对称性，但是每个模型的实际对称性个数可不是都一样的，有的模型1个对称，有的模型2个对称，有的模型可能更多，那么怎么做批处理，计算loss反传呢？读作者的代码，从 &lt;a href=https://github1s.com/GodZarathustra/SymmetryNet/blob/HEAD/lib/loss.py#L10-L11&gt;code&lt;/a&gt; 可以看到作者在每次计算loss的时候，实际上batch size为1，在 &lt;a href=https://github1s.com/GodZarathustra/SymmetryNet/blob/HEAD/tools/train_shapenet.py#L81-L82&gt;code&lt;/a&gt; 也可以看到dataloader的batch size也被设为1了，那么事情就变得明了，作者在实际实现的时候，是一个模型一个模型训练的，没有采用批处理，这也算是无奈之举。</p>

<h2 id="总结">总结</h2>

<p>Pros.</p>
<ol>
  <li>it handles RGB-D inputs, and can deal with incomplete and partial observation</li>
  <li>end-to-end deep learning method</li>
</ol>

<p>Cons:</p>
<ol>
  <li>strong supervision</li>
  <li>limited with pre-defined maximum of number of symmetries per object</li>
</ol>]]></content><author><name></name></author><category term="Geometry," /><category term="NN" /><category term="Symmetry" /><summary type="html"><![CDATA[Paper: SymmetryNet: Learning to Predict Reflectional and Rotational Symmetries of 3D Shapes from Single-View RGB-D Images]]></summary></entry></feed>